<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: bash | My Musings]]></title>
  <link href="http://blog.hyfather.com/blog/categories/bash/atom.xml" rel="self"/>
  <link href="http://blog.hyfather.com/"/>
  <updated>2013-03-03T23:28:42-08:00</updated>
  <id>http://blog.hyfather.com/</id>
  <author>
    <name><![CDATA[Nikhil Mungel]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Crafting Beautiful Command Line Applications with Ruby]]></title>
    <link href="http://blog.hyfather.com/blog/2012/09/20/crafting-beautiful-command-line-applications-with-ruby/"/>
    <updated>2012-09-20T12:47:00-07:00</updated>
    <id>http://blog.hyfather.com/blog/2012/09/20/crafting-beautiful-command-line-applications-with-ruby</id>
    <content type="html"><![CDATA[<p>Earlier this year, <a href="http://twitter.com/shishirdas" title="@shishirdas">Shishir Das</a> and I presented at RubyConf India 2012 on how to go
about crafting beautiful, utilitarian and functioning command line
applications using Ruby.</p>

<p>And then this week, I got a chance to speak about the same topic at
the Ruby Lightning Talk series organized by the great folks at
<a href="http://www.apartmentlist.com/">ApartmentList</a> and
<a href="http://thoughtbot.com/">Thoughtbot</a>Â in the heart of SoMa in San
Francisco. I condensed the
<a href="http://slidesha.re/rubycli" title="View the slideshow at slideshare.net">full-format presentation</a>
from earlier this year into this crisp 10 minute talk that I've embedded here --</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/14362934"
width="427" height="356" frameborder="0" marginwidth="0"
marginheight="0" scrolling="no" style="border:1px solid
#CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen
webkitallowfullscreen mozallowfullscreen> </iframe>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Restricted Bash]]></title>
    <link href="http://blog.hyfather.com/blog/2011/12/17/restricted-bash/"/>
    <updated>2011-12-17T09:52:00-08:00</updated>
    <id>http://blog.hyfather.com/blog/2011/12/17/restricted-bash</id>
    <content type="html"><![CDATA[<p>While working on deploying a web-application recently, I needed to transfer a 'build artifact' (fancy name for a <code>.tgz</code>) from a Continuous Integration server to an RPM repository server.</p>

<p>We already have an existing RPM repository server that uses Apache, and once my tarball was in the correct location, it would be available over HTTP for all to consume.</p>

<p>Cutting to the chase -- <em>What is the simplest way by which I could automatically transfer a ~20 MiB file from one CentOS host to another?</em>
 I didn't want to install an FTP server or any extra Apache module on the existing RPM host that would then support multi-part file uploads.</p>

<p>The quickest solution, it seemed was an <code>scp</code> or an <code>rsync</code>.</p>

<p>So, how would this CI host be authorized to open an SSH tunnel to the web-server?
 Where would the identity key reside? There is no elaborate keyserver in this ecosystem.</p>

<p>I decided to the transfer the responsibility of protecting the system from the identity key to the remote host's operating system.</p>

<p>A new user called <em>tarballs</em> on the RPM repository host with its <code>HOME</code> set to <code>/var/www/html/tarballs</code>, and set its <code>SHELL</code> to <code>rbash</code>.</p>

<h3>What is rbash?</h3>

<p>When the bash is started with the name rbash (<code>ln -s /bin/bash /bin/rbash</code>) or by invoking bash like this: <code>bash -r</code>, it starts up in a restricted way, which is handy while setting up more controlled environments. I know of it thanks to Saurabh 'Rob' Mookherjee, a sysadmin whom I work with.
 When in bash's restricted mode, one cannot change directories, use commands with a <code>/</code> in them, neither can one change the <code>PATH</code> or the <code>SHELL</code> variables. A more comprehensive list of contraints can be found in the manpage for bash.</p>

<p>So, all is good except the <em>tarballs</em> user still has access to all executables that exist in its <code>PATH</code> that the system assigns by default.
 A quick hack in the <code>/etc/profile.d</code> to unset the <code>PATH</code> for the <em>tarballs</em> user and there is hardly anything the <em>tarballs</em> user can do once logged in.
 The only required executble binary was <code>/usr/bin/ln</code> to make a symlink called 'latest' to the most recent tarball that was SCP'ed over.
 I copied this binary to <em>tarballs'</em> <code>HOME</code>. A kludge, I admit.</p>

<p>Now, from my Continuous Integration agent, I can script these two commands to be run everytime a new build artifact is to be uploaded to the repository.</p>

<pre><code>scp -v -i tarball_identity tmp/build7f3cd88.tar.gz tarballs@repo.host.com:  
ssh -v -i tarball_identity tarballs@repo.host.com "ln -sf build7f3cd88.tar.gz latest"
</code></pre>

<p>For reference, here is what I have on the repository host:</p>

<pre><code>[root@repo.host.com ~]# cat /etc/profile.d/tarballs.sh 
if [ `whoami` = 'tarballs' ]; then unset PATH; fi
</code></pre>

<p>In larger, more complicated systems that support different products and web-apps, I have seen the occasional file that is rsync'ed to another host, or a larger script residing remotely being invoked over SSH. While such things usually happen inside of a VPN or a DMZ, it is still a risky proposition to have an identity file being checked into the codebase or lying on an arbitrary host.
 While having a more robust security solution should certainly be on the list, creating a separate user on the remote host that has only enough privileges to perform a said task is a great idea.
 Once such a user exists, we have effectively moved that responsibility from the SSH identity keyfile to the remote host's operating system.</p>

<p><em>Bear in mind that this infrastructure lies in a secure corporate datacenter with access to the machines restricted to trusted co-workers. Also, while the RPM repository host is important, all the data it holds can be easily mirrored and reproduced.
 Solely relying on an <code>rbash</code> is by no means a solution for any mission-critical host that is directly exposed to the internet or any untrusted zone.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bundler and RVM]]></title>
    <link href="http://blog.hyfather.com/blog/2011/10/18/bundler/"/>
    <updated>2011-10-18T06:35:00-07:00</updated>
    <id>http://blog.hyfather.com/blog/2011/10/18/bundler</id>
    <content type="html"><![CDATA[<p>Almost everyone I know who writes any Ruby outside of the <a href="http://en.wikipedia.org/wiki/Interactive_Ruby_Shell">irb REPL</a> uses Bundler.
And <em>everyone</em> I know uses RVM to manage their rubies and their gems locally, except for this one guy who uses <a href="https://github.com/sstephenson/rbenv">rbenv</a> (which is a great tool, more on that in another blog post).</p>

<p>I have observed people use different strategies and workflows with bundler and RVM, since there is at least one overlap in what they do: manage collections of rubygems.
Bundler calles them <em>bundles</em> and RVM calles them <em>gemsets</em>.</p>

<p>Broadly, here are two patterns.</p>

<h3>Pattern #1</h3>

<p>When a new project is cloned or intialized, an RVM gemset is created with the project's name.
Then, every time one wishes to work on that project, they switch to that gemset using the .rvmrc.</p>

<h3>Pattern #2</h3>

<p>When cloning or initilizing a new project on the system, no gemsets are explicitly created in RVM.
Instead, bundler is used to manage all gemmy things across the system and across projects.</p>

<p><code>bundle install --path .gems</code></p>

<p>This <code>--path</code> helps keeping the global RVM gem-space always empty (except for bundler.gem, rake.gem and rails.gem, to initlialize new projects.)
This also results in one's <code>.bundle/config</code> file to now contain the entry</p>

<p><code>BUNDLE\_PATH: .gems</code></p>

<p>And of course, .gems should be ignored by your SCM.</p>

<p><code>echo ".gems" \&gt;\&gt; .gitignore \# if you use git.</code></p>

<p><em><strong>protip:</strong> I also include .gems when I create my tagfile. This helps me to quickly jump into the gem's codebase using my editor.</em></p>

<h3>Why do I shamelessly try selling Pattern #2 to everyone I meet?</h3>

<p>Bundler is closer to the project while RVM is closer to the system. I like to have my project's gems in my project's directory managed with a tool built for the job.</p>

<p>Bundler stays with you in production.env while RVM might not, depending on the sysadmin and the situation at hand. I uniformly work on a philosophy of keeping my development as close to production with regards to the toolchain. No, I don't run RHEL on my laptop.</p>

<p>One additional step encountered is prefixing every command that needs to run in the project context by <code>bundle exec</code> (I have it aliased to <code>bx</code>).
Which is only fair, since that is how every command would run on production.env.</p>

<p>e. g. <code>bundle exec rake db:migrate</code> or <code>bx rails dbconsole</code></p>

<p><em><strong>protip:</strong> Forgot to prefix <code>bx</code> to the previous command? Run <code>bx !!</code>.</em></p>

<p>UPDATE: @tdinkar <a href="https://twitter.com/tdinkar/status/126517974759776256">pointed me</a> to passing the <code>--binstubs</code> flag to bundle install that gets rid of having to use <code>bundle exec</code> for every executable command to be run in the bundled context.
Here is Yehuda's <a href="http://yehudakatz.com/2011/05/30/gem-versioning-and-bundler-doing-it-right/">blog post</a> delving into more detail about the <code>--binstubs</code> flag and the reason for its existence.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[XON and XOFF]]></title>
    <link href="http://blog.hyfather.com/blog/2011/10/07/xon-and-xoff/"/>
    <updated>2011-10-07T12:39:00-07:00</updated>
    <id>http://blog.hyfather.com/blog/2011/10/07/xon-and-xoff</id>
    <content type="html"><![CDATA[<h3>It started with SSH sessions to the Bangalore data center freezeing up sporadically.</h3>

<p>It wasn't all that sporadic, a pattern was noticed soon enough -- a
harmless <code>C-x C-s</code> issued when inside vi.</p>

<p>Unfortunately, most distros do not come bundled with emacs and I have to resort to botching up and fumbling with vi (or vim) to edit a few configurations now and then.
Everytime I'd tweak an LXC configuration with vim and hit <code>C-x C-s</code> on the unsuspecting editor, things would freeze up. It'd refuse to respond to even the widely respected un-interceptability of the <code>^Z</code>.
Since I use a multiplexed SSH control-master, I'd waste no time opening another SSH to the obstinate host in a different tab and mind my business.</p>

<p>Till I learned about <a href="http://en.wikipedia.org/w/index.php?title=Software_flow_control&amp;oldid=442424622" title="flow control">flow control</a>.</p>

<h3>What is software flow control?</h3>

<p>Software Flow Control enables communication links to be started or
stopped using the primary communication channel, which in this case
was the ssh tunnel.
XON and XOFF dictate the status of the data-link transmission to the
tty <em>(X stands for transmission)</em>.</p>

<p>XOFF is mapped to <code>C-s</code> by default, which causes the SSH session to not receive any signals.</p>

<p>It can be promptly remedied by an XON (mapped to <code>C-q</code> by default) to resume the transmission.</p>

<p>Emacs by default intercepts all <code>C-</code> sequences and hence does not exhibit this behaviour.</p>

<p><strong>TL;DR</strong>
SSH freezes up, 'hangs' or stops responding when you hit <code>C-s</code>?
Use <code>C-q</code> to resume it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Time Saving Bash Tricks]]></title>
    <link href="http://blog.hyfather.com/blog/2011/08/26/time-saving-bash-tricks/"/>
    <updated>2011-08-26T20:22:00-07:00</updated>
    <id>http://blog.hyfather.com/blog/2011/08/26/time-saving-bash-tricks</id>
    <content type="html"><![CDATA[<p>This is a followup from the lightning talk <strong>5 Time Saving Bash
Tricks</strong> that I gave at DevOpsDays, Bangalore 2011.</p>

<h3>SSH multiplexing</h3>

<p>Adding these to <code>~/.ssh/config</code> or <code>/etc/ssh_config</code> will allow you to
multiplex one SSH connection to open multiple terminals, multiple
<code>scp</code> and <code>git push</code> without having to authenticate over keys or passwords.</p>

<pre><code>Host \*
ControlMaster auto
ControlPath /tmp/%r0%h:%p
</code></pre>

<h3>Ensuring Bash Hisory across multiple sessions</h3>

<p>Add this to <code>~/.bashrc</code></p>

<pre><code>shopt -s histappend
</code></pre>

<h3>The rabbit hole of directories</h3>

<p>Remember to use <code>pushd</code> and <code>popd</code> when in deeply working with many
directories.</p>

<pre><code>grizzly:~$ pushd /var/log/apache2/
/var/log/apache2 ~
grizzly:apache2$ # do something
grizzly:apache2$ pushd /etc
/etc /var/log/apache2 ~
grizzly:etc$ # do something else
grizzly:etc$ popd
/var/log/apache2 ~
grizzly:apache2$ popd
~
grizzly:~$
</code></pre>

<p>In fact, you can effectively use <code>pushd</code> instead of <code>cd</code>.</p>

<h3>Background tail processes to share STDOUT and STDERR with any REPL</h3>

<pre><code>tail -f httpd.log &amp;
</code></pre>

<p>Then start the REPL, or continue working on the shell (which is also a
REPL).</p>

<h3>And finally, some copypasta on the Shell</h3>

<p><em>Note that these work with the emacs-readline, which is the default
 configuration in most distributions (including OS X).</em></p>

<script src="https://gist.github.com/hyfather/1311323.js"></script>



]]></content>
  </entry>
  
</feed>
